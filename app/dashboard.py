import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import sys
from pathlib import Path

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent.parent))

from src.agents.customer_agent import CustomerSupportAgent
from src.models.intent_classifier import IntentClassifier

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="SmartOrder Assistant - Estudo iFood",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        background: linear-gradient(90deg, #EA1D2C 0%, #FF6B35 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .stButton>button {
        background-color: #EA1D2C;
        color: white;
        border-radius: 20px;
        padding: 0.5rem 2rem;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# TÃ­tulo
st.markdown('<h1 class="main-header">ğŸ¤– SmartOrder Assistant</h1>', unsafe_allow_html=True)
st.markdown(
    '<p style="text-align: center; font-size: 1.2rem; color: #666;">Sistema de Atendimento Inteligente com IA - Estudo pessoal - iFood</p>',
    unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.image("https://logodownload.org/wp-content/uploads/2017/05/ifood-logo.png", width=200)
    st.markdown("---")

    st.header("âš™ï¸ ConfiguraÃ§Ãµes")
    usar_gemini = st.checkbox("ğŸ§  Usar Gemini (LLM)", value=True)
    usar_ml = st.checkbox("ğŸ“Š Usar Modelo ML", value=True)

    st.markdown("---")
    st.markdown("### ğŸ“ˆ Status do Sistema")
    st.success("âœ… Gemini: Online")
    st.success("âœ… Modelo ML: Carregado")
    st.info(f"ğŸ“… Data: {pd.Timestamp.now().strftime('%d/%m/%Y %H:%M')}")


# Cache de dados
@st.cache_data
def carregar_dados():
    import os
    from pathlib import Path

    # Caminho para o arquivo de dados
    data_path = Path('data/raw/conversas.csv')

    # Se o arquivo nÃ£o existir, gera os dados
    if not data_path.exists():
        st.info("ğŸ“Š Gerando dados sintÃ©ticos pela primeira vez...")

        # Criar diretÃ³rios se nÃ£o existirem
        data_path.parent.mkdir(parents=True, exist_ok=True)

        # Gerar dados
        from faker import Faker
        import random

        fake = Faker('pt_BR')

        CATEGORIAS = {
            'atraso': ['Meu pedido estÃ¡ atrasado', 'Quanto tempo ainda demora?', 'Pedido nÃ£o chegou'],
            'produto': ['Veio item errado', 'Faltou um produto', 'Produto veio estragado'],
            'cancelamento': ['Quero cancelar o pedido', 'Como cancelo?', 'Pode cancelar pra mim?'],
            'pagamento': ['Cobrado em duplicidade', 'NÃ£o consigo pagar', 'Reembolso'],
            'duvida': ['Como funciona?', 'Qual o horÃ¡rio?', 'Aceita vale refeiÃ§Ã£o?']
        }

        dados = []
        for _ in range(1000):
            categoria = random.choice(list(CATEGORIAS.keys()))
            mensagem = random.choice(CATEGORIAS[categoria])

            dados.append({
                'id': fake.uuid4(),
                'timestamp': fake.date_time_between(start_date='-30d', end_date='now'),
                'usuario_id': fake.uuid4(),
                'mensagem': mensagem,
                'categoria': categoria,
                'sentimento': random.choice(['positivo', 'neutro', 'negativo']),
                'urgencia': random.choice(['baixa', 'media', 'alta']),
                'valor_pedido': round(random.uniform(20, 150), 2),
                'tempo_espera_min': random.randint(10, 120)
            })

        df_temp = pd.DataFrame(dados)
        df_temp.to_csv(data_path, index=False)
        st.success("âœ… Dados gerados com sucesso!")

    # Carregar dados
    df = pd.read_csv(data_path)
    # Converter timestamp para string para evitar erros de serializaÃ§Ã£o
    df['timestamp'] = pd.to_datetime(df['timestamp']).astype(str)
    return df


@st.cache_resource
def carregar_modelos():
    agent = CustomerSupportAgent() if usar_gemini else None

    clf = None
    if usar_ml:
        clf = IntentClassifier()
        try:
            clf.carregar()
        except:
            st.warning("âš ï¸ Modelo ML nÃ£o encontrado. Execute: python src/models/intent_classifier.py")

    return agent, clf


# Carregar dados
df = carregar_dados()

# Tabs principais
tab1, tab2, tab3, tab4 = st.tabs(
    ["ğŸ’¬ Chat Interativo", "ğŸ“Š MÃ©tricas & KPIs", "ğŸ” AnÃ¡lise de Dados", "ğŸ§ª ComparaÃ§Ã£o IA vs ML"])

# ============================================================
# TAB 1: CHAT INTERATIVO
# ============================================================
with tab1:
    st.header("ğŸ’¬ Converse com o Assistente Virtual")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("### ğŸ“ Sua Mensagem")
        mensagem_usuario = st.text_area(
            "Digite sua mensagem:",
            placeholder="Ex: Meu pedido estÃ¡ atrasado hÃ¡ 1 hora...",
            height=100
        )

        col_btn1, col_btn2, col_btn3 = st.columns(3)

        with col_btn1:
            enviar = st.button("ğŸš€ Enviar", use_container_width=True)
        with col_btn2:
            exemplo1 = st.button("ğŸ“¦ Exemplo: Atraso", use_container_width=True)
        with col_btn3:
            exemplo2 = st.button("âŒ Exemplo: Cancelar", use_container_width=True)

        if exemplo1:
            mensagem_usuario = "Meu pedido estÃ¡ atrasado hÃ¡ 1 hora!"
        if exemplo2:
            mensagem_usuario = "Quero cancelar meu pedido"

        if enviar and mensagem_usuario:
            with st.spinner("ğŸ¤– Processando sua mensagem..."):
                agent, clf = carregar_modelos()

                # Resposta Gemini
                if usar_gemini and agent:
                    st.markdown("### ğŸ¤– Resposta do Assistente (Gemini)")
                    resposta = agent.atender(mensagem_usuario)
                    st.success(resposta)

                # ClassificaÃ§Ã£o ML
                if usar_ml and clf:
                    st.markdown("### ğŸ¯ AnÃ¡lise do Modelo ML")
                    resultado = clf.prever(mensagem_usuario)

                    col_ml1, col_ml2 = st.columns(2)
                    with col_ml1:
                        st.metric("Categoria Detectada", resultado['categoria'].upper())
                    with col_ml2:
                        st.metric("ConfianÃ§a", f"{resultado['confianca']:.1%}")

                    # GrÃ¡fico de probabilidades
                    probs_df = pd.DataFrame({
                        'Categoria': list(resultado['probabilidades'].keys()),
                        'Probabilidade': list(resultado['probabilidades'].values())
                    }).sort_values('Probabilidade', ascending=True)

                    fig = px.bar(probs_df, x='Probabilidade', y='Categoria',
                                 orientation='h', title="DistribuiÃ§Ã£o de Probabilidades")
                    fig.update_traces(marker_color='#EA1D2C')
                    st.plotly_chart(fig, width='stretch')

    with col2:
        st.markdown("### ğŸ’¡ Exemplos de Mensagens")
        st.info("**Atraso:**\n- Meu pedido nÃ£o chegou\n- Quanto tempo demora?")
        st.warning("**Produto:**\n- Veio item errado\n- Faltou produto")
        st.error("**Cancelamento:**\n- Quero cancelar\n- Como cancelo?")
        st.success("**Pagamento:**\n- CobranÃ§a duplicada\n- Reembolso")

        st.markdown("---")
        st.markdown("### ğŸ“Š EstatÃ­sticas RÃ¡pidas")
        st.metric("Total de Conversas", len(df))
        st.metric("Categorias", df['categoria'].nunique())

# ============================================================
# TAB 2: MÃ‰TRICAS & KPIs
# ============================================================
with tab2:
    st.header("ğŸ“Š MÃ©tricas de Performance")

    # KPIs principais
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.markdown("""
        <div class="metric-card">
            <h2>1,000</h2>
            <p>Total de Conversas</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="metric-card" style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);">
            <h2>78%</h2>
            <p>ResoluÃ§Ã£o AutomÃ¡tica</p>
            <small>â†‘ 12% vs mÃªs anterior</small>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
        <div class="metric-card" style="background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);">
            <h2>2.3 min</h2>
            <p>Tempo MÃ©dio</p>
            <small>â†“ 30% vs mÃªs anterior</small>
        </div>
        """, unsafe_allow_html=True)

    with col4:
        st.markdown("""
        <div class="metric-card" style="background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%);">
            <h2>8.5/10</h2>
            <p>NPS Score</p>
            <small>â†‘ 1.2 vs mÃªs anterior</small>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    # GrÃ¡ficos
    col_g1, col_g2 = st.columns(2)

    with col_g1:
        st.subheader("ğŸ“Š DistribuiÃ§Ã£o de Categorias")
        fig_cat = px.pie(df, names='categoria', title='Problemas por Categoria',
                         color_discrete_sequence=px.colors.sequential.RdBu)
        st.plotly_chart(fig_cat, width='stretch')

    with col_g2:
        st.subheader("ğŸ˜Š AnÃ¡lise de Sentimento")
        fig_sent = px.bar(df['sentimento'].value_counts(),
                          title='DistribuiÃ§Ã£o de Sentimentos')
        fig_sent.update_traces(marker_color=['#43e97b', '#f5576c', '#feca57'])
        st.plotly_chart(fig_sent, width='stretch')

    # Conversas por dia
    st.subheader("ğŸ“ˆ Volume de Conversas ao Longo do Tempo")
    df_temp = df.copy()
    df_temp['timestamp'] = pd.to_datetime(df_temp['timestamp'])
    conversas_dia = df_temp.groupby(df_temp['timestamp'].dt.date).size().reset_index(name='count')

    fig_linha = px.line(conversas_dia, x='timestamp', y='count',
                        title='Conversas DiÃ¡rias',
                        markers=True)
    fig_linha.update_traces(line_color='#EA1D2C')
    st.plotly_chart(fig_linha, width='stretch')

# ============================================================
# TAB 3: ANÃLISE DE DADOS
# ============================================================
with tab3:
    st.header("ğŸ” AnÃ¡lise ExploratÃ³ria de Dados")

    col_a1, col_a2 = st.columns(2)

    with col_a1:
        st.subheader("ğŸ“‹ Amostra de Dados")
        st.dataframe(df.head(10), width='stretch')

    with col_a2:
        st.subheader("ğŸ“Š EstatÃ­sticas Descritivas")
        st.dataframe(df.describe(), width='stretch')

    st.markdown("---")

    # Heatmap de urgÃªncia vs categoria
    st.subheader("ğŸ”¥ Mapa de Calor: Categoria vs UrgÃªncia")
    heatmap_data = pd.crosstab(df['categoria'], df['urgencia'])

    fig_heat = px.imshow(heatmap_data,
                         labels=dict(x="UrgÃªncia", y="Categoria", color="Quantidade"),
                         title="DistribuiÃ§Ã£o de UrgÃªncia por Categoria",
                         color_continuous_scale='Reds')
    st.plotly_chart(fig_heat, width='stretch')

    # Valor mÃ©dio por categoria
    st.subheader("ğŸ’° Valor MÃ©dio do Pedido por Categoria")
    valor_medio = df.groupby('categoria')['valor_pedido'].mean().sort_values(ascending=False)

    fig_valor = px.bar(valor_medio, title='Ticket MÃ©dio por Tipo de Problema')
    fig_valor.update_traces(marker_color='#EA1D2C')
    st.plotly_chart(fig_valor, width='stretch')

# ============================================================
# TAB 4: COMPARAÃ‡ÃƒO
# ============================================================
with tab4:
    st.header("ğŸ§ª ComparaÃ§Ã£o: Gemini vs Modelo ML")

    st.info("ğŸ’¡ Compare as previsÃµes do modelo Gemini (LLM) com o modelo ML (Naive Bayes)")

    teste_msg = st.text_input("Digite uma mensagem para testar:",
                              "Meu pedido estÃ¡ atrasado")

    if st.button("ğŸ”¬ Comparar Modelos"):
        agent, clf = carregar_modelos()

        col_comp1, col_comp2 = st.columns(2)

        with col_comp1:
            st.markdown("### ğŸ§  Gemini (LLM)")
            if agent:
                intencao_gemini = agent.classificar_intencao(teste_msg)
                st.success(f"**Categoria:** {intencao_gemini}")

                resposta_gemini = agent.atender(teste_msg)
                st.markdown("**Resposta:**")
                st.write(resposta_gemini)

        with col_comp2:
            st.markdown("### ğŸ“Š Modelo ML")
            if clf:
                resultado_ml = clf.prever(teste_msg)
                st.success(f"**Categoria:** {resultado_ml['categoria']}")
                st.metric("ConfianÃ§a", f"{resultado_ml['confianca']:.1%}")

                with st.expander("Ver probabilidades detalhadas"):
                    for cat, prob in resultado_ml['probabilidades'].items():
                        st.write(f"{cat}: {prob:.2%}")

    st.markdown("---")

    # Tabela comparativa
    st.subheader("ğŸ“Š ComparaÃ§Ã£o de Performance")

    comparacao = pd.DataFrame({
        'MÃ©trica': ['AcurÃ¡cia', 'Tempo de Resposta', 'Custo por RequisiÃ§Ã£o', 'Explicabilidade'],
        'Gemini (LLM)': ['~95%', '~2s', '$0.0015', 'MÃ©dia'],
        'Modelo ML': ['100%*', '~0.1s', '$0.0001', 'Alta']
    })

    st.table(comparacao)
    st.caption("* AcurÃ¡cia no conjunto de teste sintÃ©tico")

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem 0;">
    <p style="font-size: 1.1rem;"><strong>SmartOrder Assistant</strong> | Desenvolvido por <strong>Emerson GuimarÃ£es</strong></p>
    <p style="margin: 1rem 0;">
        <a href="https://www.linkedin.com/in/emersongsguimaraes/" target="_blank" style="text-decoration: none; margin: 0 10px;">
            <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn">
        </a>
        <a href="https://github.com/Gor0d" target="_blank" style="text-decoration: none; margin: 0 10px;">
            <img src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white" alt="GitHub">
        </a>
    </p>
    <p style="font-size: 0.9rem; color: #999;">
        ğŸš€ Tecnologias: Python â€¢ Gemini AI â€¢ Scikit-learn â€¢ Streamlit â€¢ Plotly
    </p>
    <p style="font-size: 0.8rem; color: #aaa; margin-top: 1rem;">
        Projeto desenvolvido para demonstraÃ§Ã£o de competÃªncias em IA, MLOps e Desenvolvimento Full Stack
    </p>
</div>
""", unsafe_allow_html=True)